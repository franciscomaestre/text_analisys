{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paco/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.svm.classes import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/seologies-python/experiments/classifier\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: './seologies-python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fa5d897cda25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./seologies-python'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#sys.path.insert(0, os.path.join(PROJECT_ROOT, \"./seologies-python/\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 2] No such file or directory: './seologies-python'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print(os.getcwd())\n",
    "os.chdir('./seologies-python')\n",
    "os.getcwd()\n",
    "#sys.path.insert(0, os.path.join(PROJECT_ROOT, \"./seologies-python/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import cPickle\n",
    "\n",
    "from core.config import settings\n",
    "from experiments.classifier.topics.extractor import getTopicList, getData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get topic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alimentación, bebida y tabaco > Alimentos\n",
    "Alimentación, bebida y tabaco > Alimentos > Carne, marisco y huevos\n",
    "Alimentación, bebida y tabaco > Alimentos > Carne, marisco y huevos > Carne\n",
    "Arte y ocio > Fiestas y celebraciones\n",
    "Arte y ocio > Fiestas y celebraciones > Productos para fiestas\n",
    "Arte y ocio > Fiestas y celebraciones > Productos para fiestas > Artículos para fiestas\n",
    "Casa y jardín > Jardín\n",
    "Casa y jardín > Jardín > Jardinería \n",
    "Casa y jardín > Jardín > Jardinería > Accesorios de jardinería\n",
    "Casa y jardín > Jardín > Jardinería > Accesorios de jardinería > Mesas de jardinería\n",
    "\n",
    "['Alimentos Alimentación, bebida y tabaco', 'Carne, marisco y huevos Alimentación, bebida y tabaco', 'Carne Alimentación, bebida y tabaco']\n",
    "\n",
    "['Fiestas y celebraciones Arte y ocio', 'Productos para fiestas Arte y ocio', 'Artículos para fiestas Arte y ocio' ]\n",
    "\n",
    "['Jardín Casa y jardín', 'Jardinería Casa y jardín', 'Accesorios de jardinería Casa y jardín', 'Mesas de jardinería Casa y jardín']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "language=u'es'\n",
    "country=u'ES'\n",
    "\n",
    "initLevel = 1\n",
    "levelHeader = 'Level %s'%initLevel\n",
    "topicList = getTopicList('experiments/classifier/data/products/taxonomy.es-ES.txt', initLevel=initLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = pd.DataFrame(topicList.items())\n",
    "topics.columns = [levelHeader, 'queries']\n",
    "topics['num_q'] = topics.apply(lambda x: len(x['queries']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#fig, axes = fig.add_subplot(nrows=1, ncols=2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "topics.plot(ax=axes[0], x=levelHeader, y='num_q', kind='hist', bins=20, legend=True, sharex=False, sharey=False)\n",
    "topics.plot(ax=axes[1], x=levelHeader, y='num_q', kind='bar', legend=True, sharex=False, sharey=False)\n",
    "#topics.plot(x='Level 0', y='num_q', kind='hist', legend=True)\n",
    "#topics.plot(x='Level 0', y='num_q', kind='bar', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from core.seo.data.seo_document_downloader import SeoDocumentDownloader\n",
    "from core.utils.translator import TranslatorFactory\n",
    "from core.seo.data.seo_library import SeoLibrary\n",
    "import random\n",
    "from core.cache.file_storage_factory import FileStorageFactory\n",
    "from core.config import settings\n",
    "from core.search_engines.google import getGoogleHost\n",
    "from core.search_engines.google.google_scraper import GoogleScraper\n",
    "from core.utils.remain_timer import RemainTimer\n",
    "from experiments.classifier.models.trainer_data import TrainerData\n",
    "TRAINER_DOWNLOAD_LIMIT = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(topics)\n",
    "print(topics.iloc[1])\n",
    "print(topics.iloc[7])\n",
    "print(topics.iloc[20])\n",
    "search_topics = {topics.iloc[1][levelHeader]: topics.iloc[1]['queries']} \n",
    "search_topics.update( {topics.iloc[7][levelHeader]: topics.iloc[7]['queries']} )\n",
    "search_topics.update( {topics.iloc[20][levelHeader]: topics.iloc[20]['queries']} )\n",
    "num_queries = sum(len(t) for t in search_topics.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _getGoogleLinks(query, language, country, downloadLimit):\n",
    "    try:\n",
    "        googleSearch = GoogleScraper(query,\n",
    "                               language=language,\n",
    "                               country=country,\n",
    "                               googleHost=getGoogleHost(country),\n",
    "                               max_results=downloadLimit)\n",
    "        print u'Links encontrados... %s' % len(googleSearch.search(True))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        \n",
    "def _getSeoDocuments(query, language, country, downloadLimit):\n",
    "    try:\n",
    "        return  SeoDocumentDownloader(query=query,\n",
    "                                       language=language,\n",
    "                                       country=country,\n",
    "                                       downloadLimit=downloadLimit,\n",
    "                                       sameOrigin=False\n",
    "                                       ).getSeoDocuments() \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return []\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download Google\n",
    "\n",
    "translator = TranslatorFactory.getTranslator()\n",
    "for topic, topicQueries in search_topics.items():\n",
    "    num_download = min(len(topicQuerys), 20)\n",
    "    \n",
    "    print(\"%s %s\"%(topic, num_download))\n",
    "    for topicQuery in topicQueries:\n",
    "        print(topicQuery)\n",
    "        _getGoogleLinks(translator.trans(topic + u' ' + topicQuery), language, country, TRAINER_DOWNLOAD_LIMIT)      \n",
    "\n",
    "print (u'GOOGLE TERMINADO -- PASAMOS A LOS DOCUMENTOS')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seoLibraries = {}\n",
    "\n",
    "for topic, topicQueries in search_topics.items():\n",
    "    seoDocuments = []\n",
    "    num_download = min(len(topicQueries), 20)\n",
    "    \n",
    "    print(\"%s %s\"%(topic, num_download))\n",
    "    for topicQuery in topicQueries:\n",
    "        print(topicQuery)\n",
    "        _getGoogleLinks(translator.trans(topic + u' ' + topicQuery), language, country, TRAINER_DOWNLOAD_LIMIT)      \n",
    "        seoDocuments.extend(_getSeoDocuments(translator.trans(topic + u' ' + topicQuery), language, country, TRAINER_DOWNLOAD_LIMIT))\n",
    "\n",
    "        \n",
    "    if len(seoDocuments) > 10:\n",
    "        seoLibraries[topic] = SeoLibrary(topic, language, country)\n",
    "        seoLibraries[topic].seoDocuments = seoDocuments        \n",
    "        \n",
    "print (u'DOCUMENTOS DESCARGADOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Juntamos datos\n",
    "\n",
    "targetList = []\n",
    "documentList = []\n",
    "for topic, seoLibrary in seoLibraries.items():\n",
    "    print u'Topic: %s Documents Downloaded: %s' % (seoLibrary.query, len(seoLibrary.seoDocuments))\n",
    "    for seoDocument in seoLibrary.seoDocuments:\n",
    "        try:\n",
    "            documentList.append(u' '.join(seoDocument.getTextTokens(lemmatize=True)))\n",
    "            targetList.append(topic)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ete3 import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classif = OneVsRestClassifier(LinearSVC(tol=0.1, dual=True, penalty='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
